{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertConfig, BertForMaskedLM, AutoTokenizer\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_to_ids(sentence_input):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentence_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): BertForMaskedLM(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BertOnlyMLMHead(\n",
       "      (predictions): BertLMPredictionHead(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\") \n",
    "\n",
    "epoch = \"0\"\n",
    "path = \"bert_trained_model_regular/\" + epoch +\"/\"\n",
    "config = BertConfig.from_pretrained( path + \"config.json\" )\n",
    "model = BertForMaskedLM.from_pretrained( path + \"pytorch_model.bin\", config=config)\n",
    "\n",
    "# setting device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "if  torch.cuda.device_count()>1:         \n",
    "    model = torch.nn.DataParallel(model,device_ids=[0,1])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj = {\"obs1\": \"Chad went to get the wheel alignment measured on his car.\", \"obs2\": \"The mechanic provided a working alignment with new body work.\", \"hyp_plus\": \"Chad was waiting for his car to be finished.\", \"hyp_minus\": \"Chad was waiting for his car to be washed.\"}\n",
    "# obj = {\"obs1\": \"Chad loves Barry Bonds.\", \"obs2\": \"Chad ensured that he took a picture to remember the event.\", \"hyp_plus\": \"Chad went to meet Barry Bonds.\", \"hyp_minus\": \"Chad failed to meet Barry Bonds.\"}\n",
    "# obj = {\"obs1\": \"Homer bought a gas grill for the summer.\", \"obs2\": \"They grilled steak for the first time on the grill.\", \"hyp_plus\": \"He wanted a steak.\", \"hyp_minus\": \"He did not like eating steaks.\"}\n",
    "obj = {\"obs1\": \"Brenna and I used to be best friends.\", \"obs2\": \"We never talked again.\", \"hyp_plus\": \"Brenna and I fought over a boy.\", \"hyp_minus\": \"Breanna and I went to the mall together.\"}\n",
    "# obj = {\"obs1\": \"My friend is a hunter.\", \"obs2\": \"The elk was nowhere to be found.\", \"hyp_plus\": \"She set up a hunting blind in the woods.\", \"hyp_minus\": \"Breanna and I went to the mall together.\"}\n",
    "\n",
    "\n",
    "obs1 = '[CLS]' + obj['obs1'] + '[SEP]'\n",
    "obs2 = obj['obs2'] + '[SEP]'\n",
    "\n",
    "obs1_word_piece = tokenizer.tokenize(obs1)\n",
    "obs2_word_piece = tokenizer.tokenize(obs2)\n",
    "\n",
    "obs1_ids = tokenizer.convert_tokens_to_ids(obs1_word_piece)\n",
    "obs2_ids = tokenizer.convert_tokens_to_ids(obs2_word_piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ -6.0291,  -5.9745,  -5.9655,  ...,  -5.4773,  -5.4335,  -3.4958],\n",
      "         [-10.5945, -10.7573, -10.7030,  ...,  -9.9779,  -9.1868,  -8.8025],\n",
      "         [ -6.9924,  -7.2248,  -6.9725,  ...,  -6.4492,  -6.4662,  -7.7672],\n",
      "         ...,\n",
      "         [-12.1683, -12.0564, -11.9398,  ..., -11.5944, -11.2568, -12.6472],\n",
      "         [-11.9891, -11.9074, -11.7754,  ..., -11.4530, -11.1173, -12.4273],\n",
      "         [-11.9553, -11.8534, -11.7369,  ..., -11.4282, -11.0813, -12.5840]]],\n",
      "       device='cuda:0', grad_fn=<GatherBackward>),)\n",
      "(tensor([[[ -8.6216,  -8.5494,  -8.4935,  ...,  -7.8683,  -7.5583,  -4.7854],\n",
      "         [-11.4656, -11.5221, -11.2541,  ..., -10.7798,  -9.3200,  -8.3493],\n",
      "         [ -6.4423,  -6.7222,  -6.3886,  ...,  -5.9790,  -5.9642,  -7.8360],\n",
      "         ...,\n",
      "         [-13.2852, -13.1841, -13.1890,  ..., -12.9669, -12.6817, -13.0162],\n",
      "         [-13.5074, -13.3998, -13.3807,  ..., -13.1408, -12.9098, -13.4225],\n",
      "         [-10.9617, -10.9643, -10.9656,  ..., -10.7707, -10.5591, -10.7506]]],\n",
      "       device='cuda:0', grad_fn=<GatherBackward>),)\n",
      "(tensor([[[ -9.6969,  -9.6000,  -9.5286,  ...,  -8.7666,  -8.4022,  -5.7318],\n",
      "         [-10.6272, -10.7802, -10.5805,  ..., -10.2681,  -7.9142,  -7.6628],\n",
      "         [ -7.6005,  -7.8109,  -7.6263,  ...,  -6.7860,  -6.0266,  -8.0400],\n",
      "         ...,\n",
      "         [-14.4104, -14.1876, -14.2623,  ..., -13.8165, -13.4204, -14.6751],\n",
      "         [-14.0641, -13.8971, -13.9352,  ..., -13.5139, -13.0367, -14.3948],\n",
      "         [-14.0276, -13.8138, -13.8845,  ..., -13.5415, -13.0342, -14.4260]]],\n",
      "       device='cuda:0', grad_fn=<GatherBackward>),)\n",
      "(tensor([[[-12.2638, -12.2406, -12.2011,  ..., -11.0642, -10.9667,  -7.5110],\n",
      "         [-10.2058, -10.3282, -10.1272,  ...,  -9.9321,  -7.6557,  -7.4548],\n",
      "         [ -7.2352,  -7.5113,  -7.3499,  ...,  -6.6698,  -5.6039,  -7.8047],\n",
      "         ...,\n",
      "         [ -9.1386,  -9.3160,  -9.2359,  ...,  -9.4887, -10.3306,  -9.0764],\n",
      "         [-15.0063, -14.9943, -14.9051,  ..., -14.7627, -15.0579, -15.6656],\n",
      "         [-12.5742, -12.6529, -12.5643,  ..., -12.7354, -13.6404, -13.3936]]],\n",
      "       device='cuda:0', grad_fn=<GatherBackward>),)\n",
      "(tensor([[[ -9.2484,  -9.2102,  -9.2210,  ...,  -8.0396,  -8.1133,  -5.1310],\n",
      "         [ -9.5091,  -9.6045,  -9.3765,  ...,  -9.3560,  -6.9615,  -7.2074],\n",
      "         [ -7.2882,  -7.5632,  -7.3465,  ...,  -6.5327,  -5.4732,  -8.0412],\n",
      "         ...,\n",
      "         [-11.4471, -11.0047, -11.1993,  ..., -11.1655, -10.7018, -11.9242],\n",
      "         [-13.7603, -13.4991, -13.6399,  ..., -13.4249, -13.2198, -14.1781],\n",
      "         [-12.0973, -11.7146, -11.9278,  ..., -11.7606, -11.5428, -12.9566]]],\n",
      "       device='cuda:0', grad_fn=<GatherBackward>),)\n",
      "(tensor([[[ -9.9246,  -9.9025,  -9.9053,  ...,  -8.6630,  -8.5827,  -5.8368],\n",
      "         [-10.3527, -10.4957, -10.2376,  ..., -10.0170,  -7.7007,  -7.5478],\n",
      "         [ -7.9136,  -8.1775,  -7.9846,  ...,  -7.0069,  -5.9948,  -8.4191],\n",
      "         ...,\n",
      "         [-15.3191, -14.9371, -15.1241,  ..., -15.4184, -15.4831, -16.1899],\n",
      "         [-13.0524, -12.8420, -12.8015,  ..., -13.0230, -12.2179, -13.5689],\n",
      "         [-12.7401, -12.5249, -12.4874,  ..., -12.6412, -11.8025, -13.3192]]],\n",
      "       device='cuda:0', grad_fn=<GatherBackward>),)\n",
      "(tensor([[[-14.4110, -14.4395, -14.3726,  ..., -12.6819, -12.9013,  -8.0339],\n",
      "         [-10.6052, -10.8045, -10.4918,  ..., -10.4626,  -8.0272,  -7.8958],\n",
      "         [ -7.1327,  -7.4441,  -7.2079,  ...,  -6.5704,  -5.5610,  -7.4971],\n",
      "         ...,\n",
      "         [-16.4753, -16.7449, -16.6735,  ..., -15.9104, -16.1819, -17.7897],\n",
      "         [-16.6035, -16.8847, -16.7987,  ..., -16.1601, -16.3679, -18.1814],\n",
      "         [-16.7316, -16.9630, -16.9108,  ..., -16.1897, -16.3223, -17.9647]]],\n",
      "       device='cuda:0', grad_fn=<GatherBackward>),)\n",
      "[CLS]Brenna and I used to be best friends.[SEP]We never talked again.[SEP]\n",
      "answer : Brenna and I fought over a boy.\n",
      "predict : brenna never met anyone .\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "token_type_ids = []\n",
    "attention_mask = []\n",
    "\n",
    "# 先append第一句 token_type為0\n",
    "for i in range(len(obs1_ids)):\n",
    "    input_ids.append(obs1_ids[i])\n",
    "    token_type_ids.append(0)\n",
    "    attention_mask.append(1)\n",
    "\n",
    "# append[MASK] token_type為1\n",
    "count = 0\n",
    "hyp = \"\"\n",
    "maskpos = len(input_ids)\n",
    "\n",
    "input_ids.append(103)\n",
    "token_type_ids.append(1)\n",
    "attention_mask.append(1)\n",
    "\n",
    "# append第三句 token_type為0\n",
    "for i in range(len(obs2_ids)):\n",
    "    input_ids.append(obs2_ids[i])\n",
    "    token_type_ids.append(0)\n",
    "    attention_mask.append(1)\n",
    "\n",
    "    \n",
    "#補齊長度為512\n",
    "while len(input_ids)<512:\n",
    "    input_ids.append(0)\n",
    "    token_type_ids.append(0)\n",
    "    attention_mask.append(0)\n",
    "\n",
    "while count < 512:\n",
    "    input_ids_tensor = torch.LongTensor([input_ids])\n",
    "    token_type_ids_tensor = torch.LongTensor([token_type_ids])\n",
    "    attention_mask_tensor = torch.LongTensor([attention_mask])\n",
    "    \n",
    "    output = model(\n",
    "        input_ids = input_ids_tensor,\n",
    "        token_type_ids = token_type_ids_tensor, \n",
    "        attention_mask = attention_mask_tensor\n",
    "    )\n",
    "    predicts = output[0]\n",
    "    predicts_index = torch.argmax(predicts[0, maskpos]).item()\n",
    "    \n",
    "    \n",
    "#     if torch.topk(predicts[0, maskpos],3,dim=-1).indices[0].item() == 102:\n",
    "#         predicts_index = torch.topk(predicts[0, maskpos],3,dim=-1).indices[1].item()\n",
    "#     else:\n",
    "#         predicts_index = torch.topk(predicts[0, maskpos],3,dim=-1).indices[1].item()\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    predicts_token = tokenizer.convert_ids_to_tokens(predicts_index)\n",
    "    \n",
    "    # --------------\n",
    "#     decode_token = tokenizer.decode(predicts_index)\n",
    "#     print(predicts_token, decode_token)\n",
    "    #-------------\n",
    "    \n",
    "    if predicts_token == \"[SEP]\":\n",
    "        break\n",
    "\n",
    "    elif predicts_token.startswith(\"##\"):\n",
    "        hyp = hyp + predicts_token[2:]\n",
    "    else:\n",
    "        hyp = hyp + \" \" + predicts_token\n",
    "\n",
    "    input_ids[maskpos] = predicts_index\n",
    "    token_type_ids[maskpos] = 1\n",
    "    attention_mask[maskpos] = 1\n",
    "    \n",
    "    maskpos += 1\n",
    "    if maskpos < 512:\n",
    "        input_ids[maskpos] = 103\n",
    "    else:\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "print(obs1 + obs2)\n",
    "print(\"answer : \" + obj['hyp_plus'])\n",
    "print(\"predict :\" + hyp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
